{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = pd.read_csv('dc.csv')\n",
    "time_df[time_df.columns[0]] = pd.to_datetime(time_df[time_df.columns[0]], format=\"%Y/%m/%d\")\n",
    "time_df.set_index(time_df.columns[0], inplace=True)\n",
    "time_df.sort_index(inplace=True)\n",
    "time_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def timeSeriesStationaryInfo(series, window):\n",
    "\n",
    "    # Plot Rolling Statistics\n",
    "    movingAverage = series.rolling(window).mean()\n",
    "    movingStd = series.rolling(window).std()\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    orig = plt.plot(series, label='Original')\n",
    "    ma = plt.plot(movingAverage, label='Moving Average')\n",
    "    mstd = plt.plot(movingStd, label='Moving Standard Deviation')\n",
    "    plt.title('Checking stationary of time series data by comparing original data with moving average and standard deviation')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    # Perform Dickey-Fuller Test\n",
    "    print('Results from Dickey-Fuller Test')\n",
    "    dftest = adfuller(series, autolag='AIC') # Find out abt AIC\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput[f'Critical Value ({key})'] = value\n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_series = time_df['volume']\n",
    "timeSeriesStationaryInfo(vol_series, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose_vol = seasonal_decompose(x=time_df[['volume']], model='additive')\n",
    "seasonal_vol = decompose_vol.seasonal\n",
    "n_period = len(np.unique(seasonal_vol))\n",
    "period_val = np.unique(seasonal_vol)\n",
    "print(n_period)\n",
    "pylab.rcParams['figure.figsize'] = (20,9)\n",
    "decompose_vol.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(np.ones_like(time_df.corr(), dtype=bool))\n",
    "sns.heatmap(time_df.corr(), mask=mask, square=True, linewidth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(time_df['volume'], lags=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ValueWarning\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_supervised(data, n_in=1, seasonal_n_in=0, period=0, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols = []\n",
    "    insert_names = []\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        for col_name in data.columns:\n",
    "            insert_names.append(col_name + (f\" (t-{i})\" if i > 0 else \" (t)\"))\n",
    "\n",
    "    # input sequene for seasonal (t-n*period, ... t-period)\n",
    "    if period > 0:\n",
    "        for i in range(seasonal_n_in, 0, -1):\n",
    "            cols.append(df.shift(i*period))\n",
    "            for col_name in data.columns:\n",
    "                insert_names.append(col_name + (f\" (t-{i*period})\" if i > 0 else \" (t)\"))\n",
    "\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        for col_name in data.columns:\n",
    "            insert_names.append(col_name + (f\" (t+{i})\" if i > 0 else \" (t)\"))\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    return pd.DataFrame(agg.values, columns=insert_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBOOST_Time_Series:\n",
    "    def __init__(self, n_estimators=1000, max_depth=10, eta=0.1, subsample=1, colsample_bytree=1):\n",
    "        self.xgb_model = XGBRegressor(n_estimators=n_estimators, max_depth=max_depth, eta=eta, subsample=subsample, colsample_bytree=colsample_bytree)\n",
    "\n",
    "    def fit(self, target_data, data, n_lag=1, seasonal_n_lag=0, period=0, n_forecast=1):\n",
    "        self.train_data = data\n",
    "        self.n_lag = n_lag\n",
    "        self.seasonal_n_lag = seasonal_n_lag\n",
    "        self.period = period\n",
    "        self.n_forecast = n_forecast\n",
    "        self.new_df = time_to_supervised(self.train_data, self.n_lag, self.seasonal_n_lag, self.period, self.n_forecast)\n",
    "        self.new_df.drop(columns=[self.train_data.columns[-1] + \" (t)\"], inplace=True)\n",
    "        self.xgb_model.fit(self.new_df, target_data.iloc[len(target_data) - len(self.new_df):])\n",
    "\n",
    "    def predict(self, pred_data):\n",
    "        self.pred_data = pd.concat([self.train_data, pred_data], axis=0)\n",
    "        self.prediction_arr = []\n",
    "        for i in range(len(pred_data)):\n",
    "            self.pred_fmt_data = time_to_supervised(self.pred_data.iloc[:len(self.pred_data)-len(pred_data)+i+1], self.n_lag, self.seasonal_n_lag, self.period, self.n_forecast, dropnan=False)\n",
    "            self.predicting_data = self.pred_fmt_data.drop(columns=[self.train_data.columns[-1] + \" (t)\"])\n",
    "            self.predicting_data.dropna(inplace=True)\n",
    "            self.pred = self.xgb_model.predict(self.predicting_data.iloc[-1:])\n",
    "            self.prediction_arr.append(self.pred[-1].tolist())\n",
    "            self.pred_data.at[self.pred_data.index[len(self.pred_data)-len(pred_data)+i], self.train_data.columns[-1]] = self.pred[-1]\n",
    "        return self.prediction_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_time_df = time_df[['open_USD', 'volume']]\n",
    "\n",
    "y = new_time_df[['volume']]\n",
    "X = new_time_df\n",
    "\n",
    "y_train_arr = []\n",
    "X_train_arr = []\n",
    "\n",
    "y_test_arr = []\n",
    "X_test_arr = []\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4, test_size=100)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    y_train_arr.append(y.iloc[train_index])\n",
    "    X_train_arr.append(X.iloc[train_index])\n",
    "    y_test_arr.append(y.iloc[test_index])\n",
    "    X_test_arr.append(X.drop(columns=['volume']).iloc[test_index])\n",
    "    # X_test_arr.append(X.iloc[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "# for n_lag in range(1,5):\n",
    "#     for s_n_lag in range(1,5):\n",
    "#         order_arr.append([n_lag, s_n_lag])\n",
    "\n",
    "for n_lag in range(1,10):\n",
    "    order_arr.append([n_lag])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    rmse_arr = []\n",
    "    for i in range(3):\n",
    "        xgbts_model = XGBOOST_Time_Series(n_estimators=1000)\n",
    "        # xgbts_model.fit(y_train_arr[i], X_train_arr[i], n_lag=order[0], seasonal_n_lag=order[1], period=7)\n",
    "        xgbts_model.fit(y_train_arr[i], X_train_arr[i], n_lag=order[0])\n",
    "        pred = xgbts_model.predict(X_test_arr[i])\n",
    "        rmse_arr.append(mean_squared_error(pred, y_test_arr[i]) ** 0.5)\n",
    "\n",
    "    # scores.append([order[0], order[1], np.mean(rmse_arr)])\n",
    "    scores.append([order[0], np.mean(rmse_arr)])\n",
    "\n",
    "# scores_df = pd.DataFrame(scores, columns=['n lag', 'seasonal lag', 'rmse'])\n",
    "scores_df = pd.DataFrame(scores, columns=['n lag', 'rmse'])\n",
    "scores_df.sort_values(by='rmse', ascending=True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 3\n",
    "xgbts_model = XGBOOST_Time_Series(n_estimators=1000)\n",
    "xgbts_model.fit(y_train_arr[v], X_train_arr[v], n_lag=3, seasonal_n_lag=2, period=7)\n",
    "# xgbts_model.fit(y_train_arr[v], X_train_arr[v], n_lag=6)\n",
    "pred = xgbts_model.predict(X_test_arr[v])\n",
    "\n",
    "print(\"RMSE: \", mean_squared_error(pred, y_test_arr[v].values) ** 0.5)\n",
    "\n",
    "plt.plot(pred, label='predicted')\n",
    "plt.plot(y_test_arr[v].values, label='actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSE: 51327.08772845146\n",
    "    - n_lags = 3\n",
    "    - seasonal_n_lags = 2\n",
    "    - period = 7\n",
    "    - test size = 100\n",
    "    - v = 3\n",
    "    - has seasonality, high variance (most closely matching that of the actual data)\n",
    "- RMSE: 56851.1820771072\n",
    "    - n_lags = 6\n",
    "    - test size = 100\n",
    "    - v = 3\n",
    "    - has some seasonality, very low variance\n",
    "- RMSE: 47565.09111563736\n",
    "    - no lags\n",
    "    - test size = 100\n",
    "    - flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=1000, max_depth=10, eta=0.1, subsample=1, colsample_bytree=1)\n",
    "xgb_model.fit(time_df.drop(columns=['volume']).iloc[:-100], time_df['volume'].iloc[:-100])\n",
    "pred = xgb_model.predict(time_df.drop(columns=['volume']).iloc[-100:])\n",
    "print(len(pred))\n",
    "print(\"RMSE: \", mean_squared_error(pred, time_df['volume'].iloc[-100:]) ** 0.5)\n",
    "plt.plot(pred, label='predicted')\n",
    "plt.plot(y_test_arr[3].values, label='actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Time_Series:\n",
    "    def __init__(self, n_neighbors):\n",
    "        self.knn_model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "\n",
    "    def fit(self, target_data, data, n_lag=1, seasonal_n_lag=0, period=0, n_forecast=1):\n",
    "        self.train_data = data\n",
    "        self.n_lag = n_lag\n",
    "        self.seasonal_n_lag = seasonal_n_lag\n",
    "        self.period = period\n",
    "        self.n_forecast = n_forecast\n",
    "        self.new_df = time_to_supervised(self.train_data, self.n_lag, self.seasonal_n_lag, self.period, self.n_forecast)\n",
    "        self.new_df.drop(columns=[self.train_data.columns[-1] + \" (t)\"], inplace=True)\n",
    "        self.knn_model.fit(self.new_df, target_data.iloc[len(target_data) - len(self.new_df):])\n",
    "\n",
    "    def predict(self, pred_data):\n",
    "        self.pred_data = pd.concat([self.train_data, pred_data], axis=0)\n",
    "        self.prediction_arr = []\n",
    "        for i in range(len(pred_data)):\n",
    "            self.pred_fmt_data = time_to_supervised(self.pred_data.iloc[:len(self.pred_data)-len(pred_data)+i+1], self.n_lag, self.seasonal_n_lag, self.period, self.n_forecast, dropnan=False)\n",
    "            self.predicting_data = self.pred_fmt_data.drop(columns=[self.train_data.columns[-1] + \" (t)\"])\n",
    "            self.predicting_data.dropna(inplace=True)\n",
    "            self.pred = self.knn_model.predict(self.predicting_data.iloc[-1:])\n",
    "            self.prediction_arr.append(self.pred[-1].tolist())\n",
    "            self.pred_data.at[self.pred_data.index[len(self.pred_data)-len(pred_data)+i], self.train_data.columns[-1]] = self.pred[-1]\n",
    "        return self.prediction_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_time_df = time_df[['open_USD', 'volume']]\n",
    "\n",
    "y = new_time_df[['volume']]\n",
    "X = new_time_df\n",
    "\n",
    "y_train_arr = []\n",
    "X_train_arr = []\n",
    "\n",
    "y_test_arr = []\n",
    "X_test_arr = []\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4, test_size=100)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    y_train_arr.append(y.iloc[train_index])\n",
    "    X_train_arr.append(X.iloc[train_index])\n",
    "    y_test_arr.append(y.iloc[test_index])\n",
    "    X_test_arr.append(X.drop(columns=['volume']).iloc[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "# for n_lag in range(1,5):\n",
    "#     for seasonal_n_lag in range(1,5):\n",
    "#         order_arr.append([n_lag, seasonal_n_lag])\n",
    "\n",
    "for n_lag in range(1, 10):\n",
    "    order_arr.append([n_lag])\n",
    "\n",
    "for k in tqdm(range(2, 15), desc='k loop'):\n",
    "    for order in tqdm(order_arr, desc='lag loop'):\n",
    "        rmse_arr = []\n",
    "        for i in range(3):\n",
    "            knnts_model = KNN_Time_Series(n_neighbors=k)\n",
    "            # knnts_model.fit(y_train_arr[i], X_train_arr[i], n_lag=order[0], seasonal_n_lag=order[1], period=7)\n",
    "            knnts_model.fit(y_train_arr[i], X_train_arr[i], n_lag=order[0])\n",
    "            pred = knnts_model.predict(X_test_arr[i])\n",
    "            # period_pred_val = np.tile(period_val, (1, math.ceil(len(pred) / n_period)))[0]\n",
    "            # period_pred_val = period_pred_val[:-(len(period_pred_val) - len(pred))]\n",
    "            # pred_period = pred + period_pred_val\n",
    "            rmse_arr.append(mean_squared_error(pred, y_test_arr[i]) ** 0.5)\n",
    "\n",
    "        # scores.append([k, order[0], order[1], np.mean(rmse_arr)])\n",
    "        scores.append([k, order[0], np.mean(rmse_arr)])\n",
    "\n",
    "# scores_df = pd.DataFrame(scores, columns=['k', 'n_lag', 'seasonal_n_lag', 'rmse'])\n",
    "scores_df = pd.DataFrame(scores, columns=['k', 'n_lag', 'rmse'])\n",
    "scores_df.sort_values(by='rmse', ascending=True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 3\n",
    "knnts_model = KNN_Time_Series(n_neighbors=13)\n",
    "# knnts_model.fit(y_train_arr[v], X_train_arr[v], n_lag=1, seasonal_n_lag=2, period=7)\n",
    "knnts_model.fit(y_train_arr[v], X_train_arr[v], n_lag=1)\n",
    "pred = knnts_model.predict(X_test_arr[v])\n",
    "\n",
    "print(\"RMSE: \", mean_squared_error(pred, y_test_arr[v].values) ** 0.5)\n",
    "\n",
    "plt.plot(pred, label='predicted')\n",
    "plt.plot(y_test_arr[v].values, label='actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSE: 45001.89115279937\n",
    "    - k = 13\n",
    "    - n_lags = 1\n",
    "    - no seasonal\n",
    "    - test size = 100\n",
    "    - v = 3\n",
    "    - very frequent seasonality, quite flat\n",
    "- RMSE: 60406.69353189595\n",
    "    - k = 5\n",
    "    - n_lags = 1\n",
    "    - seasonal_n_lags = 2\n",
    "    - test size = 100\n",
    "    - v = 3\n",
    "    - has a little seasonality, quite flat\n",
    "- RMSE: 52201.216485396195\n",
    "    - k = 5\n",
    "    - n_lag = 9\n",
    "    - test size = 100\n",
    "    - v = 3\n",
    "    - has pretty good seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in range(2, 40):\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn_model.fit(time_df.drop(columns=['volume']).iloc[:-100], time_df['volume'].iloc[:-100])\n",
    "    pred = knn_model.predict(time_df.drop(columns=['volume']).iloc[-100:])\n",
    "    scores.append([k, mean_squared_error(pred, time_df['volume'].iloc[-100:]) ** 0.5])\n",
    "scores_df = pd.DataFrame(scores, columns=['k', 'rmse'])\n",
    "\n",
    "knn_model = KNeighborsRegressor(n_neighbors=scores_df.sort_values(by='rmse', ascending=True).iloc[0, 0])\n",
    "knn_model.fit(time_df.drop(columns=['volume']).iloc[:-100], time_df['volume'].iloc[:-100])\n",
    "pred = knn_model.predict(time_df.drop(columns=['volume']).iloc[-100:])\n",
    "\n",
    "print(\"k:\", scores_df.sort_values(by='rmse', ascending=True).iloc[0, 0])\n",
    "print(\"RMSE: \", mean_squared_error(pred, time_df['volume'].iloc[-100:]) ** 0.5)\n",
    "plt.plot(pred, label='predicted')\n",
    "plt.plot(y_test_arr[3].values, label='actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVR_Time_Series:\n",
    "    def __init__(self):\n",
    "        self.svr_model = SVR()\n",
    "\n",
    "    def fit(self, target_data, data, n_lag=1, seasonal_n_lag=0, period=0, n_forecast=1):\n",
    "        self.train_data = data\n",
    "        self.n_lag = n_lag\n",
    "        self.seasonal_n_lag = seasonal_n_lag\n",
    "        self.period = period\n",
    "        self.n_forecast = n_forecast\n",
    "        self.new_df = time_to_supervised(self.train_data, self.n_lag, self.seasonal_n_lag, self.period, self.n_forecast)\n",
    "        self.new_df.drop(columns=[self.train_data.columns[-1] + \" (t)\"], inplace=True)\n",
    "        self.svr_model.fit(self.new_df, target_data.iloc[len(target_data) - len(self.new_df):])\n",
    "\n",
    "    def predict(self, pred_data):\n",
    "        self.pred_data = pd.concat([self.train_data, pred_data], axis=0)\n",
    "        self.prediction_arr = []\n",
    "        for i in range(len(pred_data)):\n",
    "            self.pred_fmt_data = time_to_supervised(self.pred_data.iloc[:len(self.pred_data)-len(pred_data)+i+1], self.n_lag, self.seasonal_n_lag, self.period, self.n_forecast, dropnan=False)\n",
    "            self.predicting_data = self.pred_fmt_data.drop(columns=[self.train_data.columns[-1] + \" (t)\"])\n",
    "            self.predicting_data.dropna(inplace=True)\n",
    "            self.pred = self.svr_model.predict(self.predicting_data.iloc[-1:])\n",
    "            self.prediction_arr.append(self.pred[-1].tolist())\n",
    "            self.pred_data.at[self.pred_data.index[len(self.pred_data)-len(pred_data)+i], self.train_data.columns[-1]] = self.pred[-1]\n",
    "        return self.prediction_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_time_df = time_df[['open_USD', 'volume']]\n",
    "\n",
    "y = new_time_df[['volume']]\n",
    "X = new_time_df\n",
    "\n",
    "y_train_arr = []\n",
    "X_train_arr = []\n",
    "\n",
    "y_test_arr = []\n",
    "X_test_arr = []\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4, test_size=100)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    y_train_arr.append(y.iloc[train_index])\n",
    "    X_train_arr.append(X.iloc[train_index])\n",
    "    y_test_arr.append(y.iloc[test_index])\n",
    "    X_test_arr.append(X.drop(columns=['volume']).iloc[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "for n_lag in range(1,10):\n",
    "    for seasonal_n_lag in range(1,10):\n",
    "        order_arr.append([n_lag, seasonal_n_lag])\n",
    "\n",
    "# for n_lag in range(1, 10):\n",
    "#     order_arr.append([n_lag])\n",
    "\n",
    "for order in tqdm(order_arr, desc='lag loop'):\n",
    "    rmse_arr = []\n",
    "    for i in range(3):\n",
    "        svrts_model = SVR_Time_Series()\n",
    "        svrts_model.fit(y_train_arr[i], X_train_arr[i], n_lag=order[0], seasonal_n_lag=order[1], period=7)\n",
    "        # svrts_model.fit(y_train_arr[i], X_train_arr[i], n_lag=order[0])\n",
    "        pred = svrts_model.predict(X_test_arr[i])\n",
    "        rmse_arr.append(mean_squared_error(pred, y_test_arr[i]) ** 0.5)\n",
    "\n",
    "    scores.append([order[0], order[1], np.mean(rmse_arr)])\n",
    "    # scores.append([order[0], np.mean(rmse_arr)])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['n_lag', 'seasonal_n_lag', 'rmse'])\n",
    "# scores_df = pd.DataFrame(scores, columns=['n_lag', 'rmse'])\n",
    "scores_df.sort_values(by='rmse', ascending=True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 3\n",
    "svrts_model = SVR_Time_Series()\n",
    "svrts_model.fit(y_train_arr[v], X_train_arr[v], n_lag=1, seasonal_n_lag=9, period=7)\n",
    "# svrts_model.fit(y_train_arr[v], X_train_arr[v], n_lag=9)\n",
    "pred = svrts_model.predict(X_test_arr[v])\n",
    "\n",
    "print(\"RMSE: \", mean_squared_error(pred, y_test_arr[v].values) ** 0.5)\n",
    "\n",
    "plt.plot(pred, label='predicted')\n",
    "plt.plot(y_test_arr[v].values, label='actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSE: 61131.72429583171\n",
    "    - n_lag = 1\n",
    "    - seasonal_n_lag = 9\n",
    "    - test size = 100\n",
    "    - v = 3\n",
    "    - straight line\n",
    "- RMSE: 62289.679460216226\n",
    "    - n_lag = 9\n",
    "    - test size = 100\n",
    "    - v = 3\n",
    "    - straight line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression_Time_Series:\n",
    "    def __init__(self):\n",
    "        self.lr_model = LinearRegression()\n",
    "\n",
    "    def fit(self, target_data, data, n_lag=1, seasonal_n_lag=0, period=0, n_forecast=1):\n",
    "        self.train_data = data\n",
    "        self.n_lag = n_lag\n",
    "        self.seasonal_n_lag = seasonal_n_lag\n",
    "        self.period = period\n",
    "        self.n_forecast = n_forecast\n",
    "        self.new_df = time_to_supervised(self.train_data, self.n_lag, self.seasonal_n_lag, self.period, self.n_forecast)\n",
    "        self.new_df.drop(columns=[self.train_data.columns[-1] + \" (t)\"], inplace=True)\n",
    "        self.lr_model.fit(self.new_df, target_data.iloc[len(target_data) - len(self.new_df):])\n",
    "\n",
    "    def predict(self, pred_data):\n",
    "        self.pred_data = pd.concat([self.train_data, pred_data], axis=0)\n",
    "        self.prediction_arr = []\n",
    "        for i in range(len(pred_data)):\n",
    "            self.pred_fmt_data = time_to_supervised(self.pred_data.iloc[:len(self.pred_data)-len(pred_data)+i+1], self.n_lag, self.seasonal_n_lag, self.period, self.n_forecast, dropnan=False)\n",
    "            self.predicting_data = self.pred_fmt_data.drop(columns=[self.train_data.columns[-1] + \" (t)\"])\n",
    "            self.predicting_data.dropna(inplace=True)\n",
    "            self.pred = self.lr_model.predict(self.predicting_data.iloc[-1:])\n",
    "            self.prediction_arr.append(self.pred[-1].tolist())\n",
    "            self.pred_data.at[self.pred_data.index[len(self.pred_data)-len(pred_data)+i], self.train_data.columns[-1]] = self.pred[-1]\n",
    "        return self.prediction_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_time_df = time_df[['open_USD', 'volume']]\n",
    "\n",
    "y = new_time_df[['volume']]\n",
    "X = new_time_df\n",
    "\n",
    "y_train_arr = []\n",
    "X_train_arr = []\n",
    "\n",
    "y_test_arr = []\n",
    "X_test_arr = []\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4, test_size=100)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    y_train_arr.append(y.iloc[train_index])\n",
    "    X_train_arr.append(X.iloc[train_index])\n",
    "    y_test_arr.append(y.iloc[test_index])\n",
    "    X_test_arr.append(X.drop(columns=['volume']).iloc[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "# for n_lag in range(1,10):\n",
    "#     for s_n_lag in range(1,10):\n",
    "#         order_arr.append([n_lag, s_n_lag])\n",
    "\n",
    "for n_lag in range(1,10):\n",
    "    order_arr.append([n_lag])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    rmse_arr = []\n",
    "    for i in range(3):\n",
    "        lrts_model = LinearRegression_Time_Series()\n",
    "        # lrts_model.fit(y_train_arr[i], X_train_arr[i], n_lag=order[0], seasonal_n_lag=order[1], period=7)\n",
    "        lrts_model.fit(y_train_arr[i], X_train_arr[i], n_lag=order[0])\n",
    "        pred = lrts_model.predict(X_test_arr[i])\n",
    "        rmse_arr.append(mean_squared_error(pred, y_test_arr[i]) ** 0.5)\n",
    "        \n",
    "    # scores.append([order[0], order[1], np.mean(rmse_arr)])\n",
    "    scores.append([order[0], np.mean(rmse_arr)])\n",
    "\n",
    "# scores_df = pd.DataFrame(scores, columns=['n lag', 'seasonal lag', 'rmse'])\n",
    "scores_df = pd.DataFrame(scores, columns=['n lag', 'rmse'])\n",
    "scores_df.sort_values(by='rmse', ascending=True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 3\n",
    "lrts_model = LinearRegression_Time_Series()\n",
    "lrts_model.fit(y_train_arr[v], X_train_arr[v], n_lag=9, seasonal_n_lag=5, period=7)\n",
    "# lrts_model.fit(y_train_arr[v], X_train_arr[v], n_lag=3)\n",
    "pred = lrts_model.predict(X_test_arr[v])\n",
    "\n",
    "print(\"RMSE: \", mean_squared_error(pred, y_test_arr[v].values) ** 0.5)\n",
    "\n",
    "plt.plot(pred, label='predicted')\n",
    "plt.plot(y_test_arr[v].values, label='actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSE: 61824.225984872195\n",
    "    - n_lag = 9\n",
    "    - seasonal_n_lag = 5\n",
    "    - test size = 100\n",
    "    - v = 3\n",
    "    - straight line\n",
    "- RMSE: 62434.37767652163\n",
    "    - n_lag = 3\n",
    "    - test size = 100\n",
    "    - v = 3\n",
    "    - straight line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_tuning(train_df, test_df, v_range, max_order, max_seasonal_order=[], period=0):\n",
    "    scores = []\n",
    "    order_arr = []\n",
    "    if max_seasonal_order == []:\n",
    "        for q in range(1, max_order[0]):\n",
    "            for d in range(max_order[1]):\n",
    "                for p in range(1, max_order[2]):\n",
    "                    order_arr.append([[q,d,p]])\n",
    "    else:\n",
    "        for q in range(1, max_order[0]):\n",
    "            for d in range(max_order[1]):\n",
    "                for p in range(1, max_order[2]):\n",
    "                    for Q in range(max_seasonal_order[0]):\n",
    "                        for D in range(max_seasonal_order[1]):\n",
    "                            for P in range(max_seasonal_order[2]):\n",
    "                                order_arr.append([[q,d,p], [Q,D,P,period]])\n",
    "\n",
    "    for order in tqdm(order_arr):\n",
    "        rmse_arr = []\n",
    "        aic_arr = []\n",
    "        for v in range(v_range):\n",
    "            exog_df = train_df[v].iloc[:, :-1]\n",
    "            endog_df = train_df[v].iloc[:, -1]\n",
    "\n",
    "            exog_test = test_df[v].iloc[:, :-1]\n",
    "            endog_test = test_df[v].iloc[:, -1]\n",
    "\n",
    "            n = len(test_df[v].index)\n",
    "\n",
    "            try:\n",
    "                if max_seasonal_order == []:\n",
    "                    arima_model = ARIMA(endog=endog_df, exog=exog_df, order=order[0])\n",
    "                else:\n",
    "                    arima_model = ARIMA(endog=endog_df, exog=exog_df, order=order[0], seasonal_order=order[1])\n",
    "                arima_result = arima_model.fit()\n",
    "                fc = arima_result.forecast(steps=n, exog=exog_test)\n",
    "                rmse_arr.append(mean_squared_error(fc, endog_test) ** 0.5)\n",
    "                aic_arr.append(arima_result.aic)\n",
    "            except: continue\n",
    "        \n",
    "        if max_seasonal_order == []:\n",
    "            scores.append([order[0][0], order[0][1], order[0][2], np.mean(aic_arr), np.mean(rmse_arr)])\n",
    "        else:\n",
    "            scores.append([order[0][0], order[0][1], order[0][2], order[1][0], order[1][1], order[1][2], np.mean(aic_arr), np.mean(rmse_arr)])\n",
    "\n",
    "    if max_seasonal_order == []: return  pd.DataFrame(scores, columns=['p', 'd', 'q', 'aic', 'rmse'])\n",
    "    else: return pd.DataFrame(scores, columns=['p', 'd', 'q', 'P', 'D', 'Q', 'aic', 'rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits=4, test_size=100)\n",
    "\n",
    "train_df, test_df = [], []\n",
    "\n",
    "for train_i, test_i in tss.split(time_df):\n",
    "    train_df.append(time_df.iloc[train_i])\n",
    "    test_df.append(time_df.iloc[test_i])\n",
    "    # train_df.append(time_df[['open_USD', 'volume']].iloc[train_i])\n",
    "    # test_df.append(time_df[['open_USD', 'volume']].iloc[test_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = arima_tuning(train_df, test_df, 3, (3,3,3), max_seasonal_order=(2,2,2), period=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rmse : \\n\", scores_df.sort_values(by='rmse', ascending=True).head(1))\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 3\n",
    "exog_df = train_df[v].iloc[:, :-1]\n",
    "endog_df = train_df[v].iloc[:, -1]\n",
    "\n",
    "exog_test = test_df[v].iloc[:, :-1]\n",
    "endog_test = test_df[v].iloc[:, -1]\n",
    "\n",
    "n = len(test_df[v].index)\n",
    "\n",
    "arima_model = ARIMA(endog=endog_df, exog=exog_df, order=(1,0,1), seasonal_order=(1,0,1,7))\n",
    "# arima_model = ARIMA(endog=endog_df, exog=exog_df, order=(1,0,2), seasonal_order=(0,1,1,7))\n",
    "arima_result = arima_model.fit()\n",
    "fc = arima_result.forecast(steps=n, exog=exog_test)\n",
    "print('RMSE: ', mean_squared_error(fc, endog_test) ** 0.5)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.plot(fc, label='prediction')\n",
    "plt.plot(endog_test, label='actual')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "### RMSE 74743.56986169254 ## RMSE metric | order = (1,0,1) | seasonal order = (1,1,1,7) | test size = 100\n",
    "### RMSE 385057918.3019191 ## AIC metric | order = (1,2,2) | seasonal order = (1,0,1,7) | test size = 100\n",
    "### RMSE 48113.173750691385 ## AIC metric | order = (1,2,2) | seasonal order = (0,0,1,7) | test size = 20\n",
    "### RMSE 44961.00223276705 ## AIC metric | order = (1,0,1) | seasonal order = (0,1,1,7) | test size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSE: 74743.56986169254\n",
    "    - RMSE metric\n",
    "    - order = (1,0,1)\n",
    "    - seasonal_order = (1,1,1,7)\n",
    "    - test size = 100\n",
    "- RMSE: 385057918.3019191\n",
    "    - AIC metric\n",
    "    - order = (1,2,2)\n",
    "    - seasonal_order = (1,0,1,7)\n",
    "    - test size = 100\n",
    "- RMSE: 98495.86596233559\n",
    "    - RMSE metric\n",
    "    - order = (1,1,2)\n",
    "    - seasonal_order = (0,1,1,7)\n",
    "    - test size = 60\n",
    "- RMSE: 126240.64247175687\n",
    "    - AIC metric\n",
    "    - order = (1,0,1)\n",
    "    - seasonal_order = (0,1,1,7)\n",
    "    - test size = 60\n",
    "- RMSE: 42198.0083154924\n",
    "    -  RMSE metric\n",
    "    - order = (2,0,1)\n",
    "    - test size = 60\n",
    "    - removed other correlated variables\n",
    "- RMSE: 41501.67554212661\n",
    "    - AIC metric\n",
    "    - order = (2,0,2)\n",
    "    - seasonal_order = (0,1,1,7)\n",
    "    - test size = 60\n",
    "    - removed other correlated variables\n",
    "- RMSE: 61971.889367297226\n",
    "    - AIC metric\n",
    "    - order = (1,0,2)\n",
    "    - seasonal_order = (0,1,1)\n",
    "    - test size = 100\n",
    "    - removed other correlated variables\n",
    "- RMSE: 42140.29575194003\n",
    "    - RMSE metric\n",
    "    - order = (1,0,1)\n",
    "    - seasonal_order = (1,0,1)\n",
    "    - test size = 100\n",
    "    - removed other correlated variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Dataset: https://www.kaggle.com/datasets/szrlee/stock-time-series-20050101-to-20171231?select=AABA_2006-01-01_to_2018-01-01.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d5babd99a4df02ec48601645cc9db139875b0384e29e5b3b3c9a97142b6b19c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
